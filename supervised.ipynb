{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with importing the modules and loading the 3 dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.unsupervised_learning import *\n",
    "\n",
    "from sklearn import svm, tree, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary dataframe shape: (10070, 1927)\n",
      "PCA 2D dataframe shape: (10070, 26)\n",
      "PCA 3D dataframe shape: (10070, 32)\n"
     ]
    }
   ],
   "source": [
    "bin_df = pd.read_csv('data/dataframes/df_after_cols_reduction.csv').iloc[:,1:]\n",
    "pca_2d_df = pd.read_csv('data/dataframes/pca_2d_df.csv').iloc[:,1:]\n",
    "pca_3d_df = pd.read_csv('data/dataframes/pca_3d_df.csv').iloc[:,1:]\n",
    "\n",
    "print(f'Binary dataframe shape: {bin_df.shape}')\n",
    "print(f'PCA 2D dataframe shape: {pca_2d_df.shape}')\n",
    "print(f'PCA 3D dataframe shape: {pca_3d_df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['company_name', 'company_about','founded', 'business model','employees','product stage','status','funding stage','succeeded']\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price', 'geo_market_per']\n",
    "tag_cols = [col for col in bin_df.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in bin_df.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in bin_df.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col  for col in bin_df.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col  for col in bin_df.columns if col.startswith(\"technology_\")]\n",
    "\n",
    "\n",
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "pca_2d_cols = [col for col in pca_2d_df.columns if col not in cat_cols and col not in num_cols]\n",
    "pca_3d_cols = [col for col in pca_3d_df.columns if col not in cat_cols and col not in num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cols : 9\n",
      "Numerical cols : 5\n",
      "Tag cols : 1599\n",
      "Targetmarket cols : 117\n",
      "Sector cols : 41\n",
      "Industry cols : 81\n",
      "Technology cols : 75\n",
      "---- Totals ----\n",
      "Total binary cols : 1913\n",
      "Toatl PCA 2D cols : 12\n",
      "Total PCA 3D cols : 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Categorical cols : {len(cat_cols)}\")\n",
    "print(f\"Numerical cols : {len(num_cols)}\")\n",
    "print(f\"Tag cols : {len(tag_cols)}\")\n",
    "print(f\"Targetmarket cols : {len(targetmarket_cols)}\")\n",
    "print(f\"Sector cols : {len(sector_list)}\")\n",
    "print(f\"Industry cols : {len(target_ind_list)}\")\n",
    "print(f\"Technology cols : {len(technology_list)}\")\n",
    "print('---- Totals ----')\n",
    "print(f\"Total binary cols : {len(bin_cols)}\")\n",
    "print(f\"Toatl PCA 2D cols : {len(pca_2d_cols)}\")\n",
    "print(f\"Total PCA 3D cols : {len(pca_3d_cols)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this noteook, we will train few machine learning models on our datasets to find the best model to predict the target variable.  \n",
    "The models we will use are:\n",
    "- [Logistic Regression](#lr)\n",
    "- [K-Nearest Neighbours](#knn)\n",
    "- [Decision Tree](#dt)\n",
    "- [Random Forest](#rf)\n",
    "- [Support Vector Machine](#svm)\n",
    "- [Gaussian Naive Bayes](#gnb)\n",
    "- [Multi-layer Perceptron](#mlp)  \n",
    "\n",
    "We will save the scores and models in a directory to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models and scores dictionary\n",
    "\n",
    "models_scores_dic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to prepare our data.  \n",
    "As we saw in the visualizations, we have almost 70% of successful companies in the dataset.  \n",
    "In order to avoid biased results, we need to train the models on an evenly distributed succeeded column in the dataset.  \n",
    "i.e the train data should contain 50% succesfull companies and 50% failed companies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary equal dataframe shape: (6122, 1927)\n",
      "Binary equal dataframe succeeded companies: 3061.0\n"
     ]
    }
   ],
   "source": [
    "bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "size = min(bin_df_succeeded.shape[0], bin_df_failed.shape[0])\n",
    "\n",
    "bin_df_failed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "bin_df_succeded_sampled = bin_df_succeeded.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([bin_df_succeded_sampled, bin_df_failed_sampled])\n",
    "\n",
    "print(f'Binary equal dataframe shape: {equal_df.shape}')\n",
    "print(f\"Binary equal dataframe succeeded companies: {equal_df['succeeded'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for both pca dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D PCA data:\n",
      "2D PCA equal dataframe shape: (6122, 26)\n",
      "2D PCA equal dataframe succeeded companies: 3061.0\n",
      "\n",
      "3D PCA data:\n",
      "3D PCA equal dataframe shape: (6122, 32)\n",
      "3D PCA equal dataframe succeeded companies: 3061.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2D PCA data:\")\n",
    "\n",
    "pca_2d_df_succeeded = pca_2d_df[pca_2d_df['succeeded'] == 1]\n",
    "pca_2d_df_failed = pca_2d_df[pca_2d_df['succeeded'] == 0]\n",
    "\n",
    "size = min(pca_2d_df_succeeded.shape[0], pca_2d_df_failed.shape[0])\n",
    "\n",
    "pca_2d_df_succeded_sampled = pca_2d_df_succeeded.sample(n = size , random_state = 42)\n",
    "pca_2d_df_failed_sampled = pca_2d_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "pca_2d_equal_df = pd.concat([pca_2d_df_succeded_sampled, pca_2d_df_failed_sampled])\n",
    "\n",
    "print(f'2D PCA equal dataframe shape: {pca_2d_equal_df.shape}')\n",
    "print(f\"2D PCA equal dataframe succeeded companies: {pca_2d_equal_df['succeeded'].sum()}\")\n",
    "\n",
    "print(\"\\n3D PCA data:\")\n",
    "\n",
    "pca_3d_df_succeeded = pca_3d_df[pca_3d_df['succeeded'] == 1]\n",
    "pca_3d_df_failed = pca_3d_df[pca_3d_df['succeeded'] == 0]\n",
    "\n",
    "size = min(pca_3d_df_succeeded.shape[0], pca_3d_df_failed.shape[0])\n",
    "\n",
    "pca_3d_df_succeded_sampled = pca_3d_df_succeeded.sample(n = size , random_state = 42)\n",
    "pca_3d_df_failed_sampled = pca_3d_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "pca_3d_equal_df = pd.concat([pca_3d_df_succeded_sampled, pca_3d_df_failed_sampled])\n",
    "\n",
    "print(f'3D PCA equal dataframe shape: {pca_3d_equal_df.shape}')\n",
    "print(f\"3D PCA equal dataframe succeeded companies: {pca_3d_equal_df['succeeded'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_XTrain shape: (4897, 1913)\n",
      "bin_yTrain shape: (4897,)\n",
      "bin_XTest shape: (1225, 1913)\n",
      "bin_yTest shape: (1225,)\n"
     ]
    }
   ],
   "source": [
    "bin_XTrain, bin_XTest, bin_yTrain, bin_yTest = train_test_split(equal_df[bin_cols], equal_df['succeeded'], test_size=0.2, random_state=42, stratify=equal_df['succeeded'])\n",
    "pca_2d_XTrain, pca_2d_XTest, pca_2d_yTrain, pca_2d_yTest = train_test_split(pca_2d_equal_df[pca_2d_cols], pca_2d_equal_df['succeeded'], test_size=0.2, random_state=42, stratify=pca_2d_equal_df['succeeded'])\n",
    "pca_3d_XTrain, pca_3d_XTest, pca_3d_yTrain, pca_3d_yTest = train_test_split(pca_3d_equal_df[pca_3d_cols], pca_3d_equal_df['succeeded'], test_size=0.2, random_state=42, stratify=pca_3d_equal_df['succeeded'])\n",
    "\n",
    "\n",
    "print(f\"bin_XTrain shape: {bin_XTrain.shape}\")\n",
    "print(f\"bin_yTrain shape: {bin_yTrain.shape}\")\n",
    "\n",
    "print(f\"bin_XTest shape: {bin_XTest.shape}\")\n",
    "print(f\"bin_yTest shape: {bin_yTest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(df, cols):\n",
    "    cv = ShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "    clf = LogisticRegression(max_iter=150)\n",
    "\n",
    "    scores = cross_val_score(clf, df[cols], df['succeeded'], cv=cv, scoring='f1_macro')\n",
    "    return scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(XTrain, yTrain):\n",
    "\n",
    "    parameters = {'n_neighbors':range(2,50,2), 'weights':['uniform', 'distance']}\n",
    "    knn = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn, parameters,scoring=metrics.make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(XTrain, yTrain)\n",
    "    return clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(XTrain, yTrain):\n",
    "    parameters = {'C':[0.1,1,10,100,1000], 'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "    s = svm.SVC()\n",
    "    clf = GridSearchCV(s, parameters,scoring=metrics.make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(XTrain, yTrain)\n",
    "    return clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnb(XTrain, yTrain, XTest, yTest):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(XTrain, yTrain)\n",
    "    y_pred = gnb.predict(XTest)\n",
    "    return metrics.f1_score(yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dt(XTrain, yTrain, XTest, yTest):\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    dt.fit(XTrain, yTrain)\n",
    "    y_pred = dt.predict(XTest)\n",
    "    return dt.score(yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(XTrain, yTrain, XTest, yTest):\n",
    "    rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "    rf.fit(XTrain, yTrain)\n",
    "    y_pred = rf.predict(XTest)\n",
    "    return metrics.f1_score(yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(XTrain, yTrain, XTest, yTest):\n",
    "    best_score = []\n",
    "    for solve in ['lbfgs', 'sgd', 'adam']:\n",
    "        mlp = MLPClassifier(solver=solve, hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "        mlp.fit(XTrain, yTrain)\n",
    "        y_pred = mlp.predict(XTest)\n",
    "        best_score.append(metrics.f1_score(yTest, y_pred))\n",
    "    return max(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 1. 1. ... 0. 0. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23584/1321851586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# scores['SVM'] = train_svm(XTrain, yTrain)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GNB'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_gnb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DT'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# scores['RF'] = train_rf(XTrain, yTrain, XTest, yTest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# scores['MLP'] = train_mlp(XTrain, yTrain, XTest, yTest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23584/2031097815.py\u001b[0m in \u001b[0;36mtrain_dt\u001b[1;34m(XTrain, yTrain, XTest, yTest)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m    466\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             if issparse(X) and (\n\u001b[0;32m    435\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 1. 1. ... 0. 0. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "dfs_scores = {}\n",
    "dfs ={'bin_df': (bin_df,bin_cols), 'pca_2d_df': (pca_2d_df,pca_2d_cols), 'pca_3d_df': (pca_3d_df,pca_3d_cols)}\n",
    "for key, df in dfs.items():\n",
    "    scores = {} \n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(df[0][df[1]], df[0]['succeeded'], test_size=0.2, random_state=42, stratify=df[0]['succeeded'])\n",
    "\n",
    "    scores['LogisticRegression'] = train_logistic_regression(df[0], df[1])\n",
    "    scores['KNN'] = train_knn(XTrain, yTrain)\n",
    "    # scores['SVM'] = train_svm(XTrain, yTrain)\n",
    "    scores['GNB'] = train_gnb(XTrain, yTrain, XTest, yTest)\n",
    "    scores['DT'] = train_dt(XTrain, yTrain, XTest, yTest)\n",
    "    # scores['RF'] = train_rf(XTrain, yTrain, XTest, yTest)\n",
    "    # scores['MLP'] = train_mlp(XTrain, yTrain, XTest, yTest)\n",
    "\n",
    "    dfs_scores[key] = scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bin_df': {'LogisticRegression': 0.6040409344741021},\n",
       " 'pca_2d_df': {'LogisticRegression': 0.41885964912280704},\n",
       " 'pca_3d_df': {'LogisticRegression': 0.4499967766428377}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(max_iter = 150)\n",
    "# lr.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain_pred = lr.predict(Xtrain)\n",
    "# ytest_pred = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train results:\")\n",
    "# print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"---------------------\")\n",
    "# print(\"Test results:\")\n",
    "# print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a new dataframe with succeeded = 1 and succeeded = 0\n",
    "\n",
    "# bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "# bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "# size = bin_df_succeeded.shape[0]\n",
    "# bin_df_fialed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "# equal_df = pd.concat([bin_df_succeeded, bin_df_fialed_sampled])\n",
    "\n",
    "# print(equal_df.shape)\n",
    "# print(equal_df['succeeded'].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain, Xtest, ytrain, ytest = train_test_split(equal_df[num_cols + bin_cols], equal_df['succeeded'],test_size = 0.2)\n",
    "# lr = LogisticRegression()\n",
    "# lr.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain_pred = lr.predict(Xtrain)\n",
    "# ytest_pred = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train results:\")\n",
    "# print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"---------------------\")\n",
    "# print(\"Test results:\")\n",
    "# print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain, Xtest, ytrain, ytest = train_test_split(equal_df[bin_cols], equal_df['succeeded'],test_size = 0.2)\n",
    "\n",
    "# print(f\"Xtrain shape: {Xtrain.shape}\")\n",
    "# print(f\"ytrain shape: {ytrain.shape}\")\n",
    "# print(f\"Xtest shape: {Xtest.shape}\")\n",
    "# print(f\"ytest shape: {ytest.shape}\")\n",
    "\n",
    "# lr = LogisticRegression(max_iter=1500)\n",
    "# lr.fit(Xtrain, ytrain)\n",
    "\n",
    "# ytrain_pred = lr.predict(Xtrain)\n",
    "# ytest_pred = lr.predict(Xtest)\n",
    "\n",
    "# print(\"\\n\\nTrain results:\")\n",
    "# print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "# print(\"---------------------\")\n",
    "# print(\"Test results:\")\n",
    "# print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "# print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "# bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "# size = bin_df_succeeded.shape[0]\n",
    "# bin_df_fialed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "# equal_df = pd.concat([bin_df_succeeded, bin_df_fialed_sampled])\n",
    "\n",
    "# print(equal_df.shape)\n",
    "# print(equal_df['succeeded'].sum())\n",
    "\n",
    "# # print(get_best_init_params_for_k_means(equal_df[bin_cols],8,['k-means++','random'],range(5,50,5),42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score after cross-validation: 0.6201803664005068\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.514350687019465, Best parameters: {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aba4874e8d4cb8a4ecae1dce5d50d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "Accuracy: 0.5771428571428572\n",
      "Precision: 0.5830388692579506\n",
      "Recall: 0.5392156862745098\n",
      "F1: 0.5602716468590833\n",
      "\n",
      "poly\n",
      "Accuracy: 0.603265306122449\n",
      "Precision: 0.6863905325443787\n",
      "Recall: 0.3790849673202614\n",
      "F1: 0.48842105263157887\n",
      "\n",
      "rbf\n",
      "Accuracy: 0.6342857142857142\n",
      "Precision: 0.6366666666666667\n",
      "Recall: 0.6241830065359477\n",
      "F1: 0.6303630363036303\n",
      "\n",
      "sigmoid\n",
      "Accuracy: 0.6122448979591837\n",
      "Precision: 0.6261510128913443\n",
      "Recall: 0.5555555555555556\n",
      "F1: 0.5887445887445888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# with tqdm.tqdm(total = len(kernels)) as pbar:\n",
    "#     for k in kernels:\n",
    "#         clf = svm.SVC(kernel=k, C=1, random_state=42)\n",
    "#         clf.fit(bin_XTrain, bin_yTrain)\n",
    "#         y_pred = clf.predict(bin_XTest)\n",
    "#         print(k)\n",
    "#         print(f'Accuracy: {metrics.accuracy_score(bin_yTest, y_pred)}')\n",
    "#         print(f'Precision: {metrics.precision_score(bin_yTest, y_pred)}')\n",
    "#         print(f'Recall: {metrics.recall_score(bin_yTest, y_pred)}')\n",
    "#         print(f'F1: {metrics.f1_score(bin_yTest, y_pred)}\\n')\n",
    "#         pbar.update(1)\n",
    "#         models_scores_dic[f'SVC_{k}'] = metrics.f1_score(bin_yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4922448979591837\n",
      "Precision: 0.49490835030549896\n",
      "Recall: 0.7941176470588235\n",
      "F1: 0.6097867001254705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5689795918367347\n",
      "Precision: 0.5664556962025317\n",
      "Recall: 0.5849673202614379\n",
      "F1: 0.5755627009646302\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6236734693877551\n",
      "Precision: 0.6215780998389694\n",
      "Recall: 0.630718954248366\n",
      "F1: 0.6261151662611516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5583673469387755\n",
      "Precision: 0.5606837606837607\n",
      "Recall: 0.5359477124183006\n",
      "F1: 0.5480367585630743\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.603265306122449\n",
      "Precision: 0.6022727272727273\n",
      "Recall: 0.6062091503267973\n",
      "F1: 0.6042345276872965\n",
      "\n",
      "Accuracy: 0.5746938775510204\n",
      "Precision: 0.5737439222042139\n",
      "Recall: 0.5784313725490197\n",
      "F1: 0.5760781122864117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # clf = MLPClassifier(solver=solve, alpha=1e-5, random_state=42, max_iter=1000)\n",
    "    # clf.fit(bin_XTrain, bin_yTrain)\n",
    "    # y_pred = clf.predict(bin_XTest)\n",
    "    # print(f'Accuracy: {metrics.accuracy_score(bin_yTest, y_pred)}')\n",
    "    # print(f'Precision: {metrics.precision_score(bin_yTest, y_pred)}')\n",
    "    # print(f'Recall: {metrics.recall_score(bin_yTest, y_pred)}')\n",
    "    # print(f'F1: {metrics.f1_score(bin_yTest, y_pred)}\\n')\n",
    "    # models_scores_dic[f'MLP_{solve}'] = metrics.f1_score(bin_yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303630363036303"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(models_scores_dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score after cross-validation: 0.4499967766428377\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(max_iter=150)\n",
    "\n",
    "scores = cross_val_score(clf, pca_3d_df[pca_3d_cols], pca_3d_df['succeeded'], cv=cv, scoring='f1_macro')\n",
    "# print(scores)\n",
    "# models_scores_dic['LogisticRegression'] = scores.max()\n",
    "print(f'Best score after cross-validation: {scores.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67974180734856\n",
      "Precision: 0.7164093767867353\n",
      "Recall: 0.8937232524964337\n",
      "F1: 0.7953030783878133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(pca_2d_XTrain,pca_2d_yTrain)\n",
    "y_pred = gnb.predict(pca_2d_XTest)\n",
    "print(f'Accuracy: {metrics.accuracy_score(pca_2d_yTest, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(pca_2d_yTest, y_pred)}')\n",
    "print(f'Recall: {metrics.recall_score(pca_2d_yTest, y_pred)}')\n",
    "print(f'F1: {metrics.f1_score(pca_2d_yTest, y_pred)}\\n')\n",
    "# models_scores_dic['GNB'] = metrics.f1_score(pca_2d_yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625124131082423\n",
      "Precision: 0.7501933488012374\n",
      "Recall: 0.6918687589158345\n",
      "F1: 0.719851576994434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(pca_3d_XTrain,pca_3d_yTrain)\n",
    "y_pred = gnb.predict(pca_3d_XTest)\n",
    "print(f'Accuracy: {metrics.accuracy_score(pca_3d_yTest, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(pca_3d_yTest, y_pred)}')\n",
    "print(f'Recall: {metrics.recall_score(pca_3d_yTest, y_pred)}')\n",
    "print(f'F1: {metrics.f1_score(pca_3d_yTest, y_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d8353be1dd092e57b3f2779bafc40fd4a1c87861698b48ff47a5f1df7325f59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
