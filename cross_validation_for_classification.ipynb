{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# === CELL TYPE: IMPORTS AND SETUP \n",
    "\n",
    "import os                       # for testing use only\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# -------- classification\n",
    "import sklearn\n",
    "from sklearn import neighbors, tree, ensemble, naive_bayes, svm\n",
    "# *** KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# *** Decision Tree; Random Forest\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# *** Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# *** SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "# --------  metrics:\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    return pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_str_to_numeric_vals(dataset):\n",
    "    df = dataset.copy()\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] = sklearn.preprocessing.LabelEncoder().fit_transform(df[col])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_and_test(dataset, label_column, test_ratio, rand_state):\n",
    "    X = dataset[dataset.columns[dataset.columns!=label_column]]\n",
    "    y = dataset[label_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=rand_state)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_obj(classifier_name, params):\n",
    "    if classifier_name == \"KNN\":\n",
    "        if params:\n",
    "            return KNeighborsClassifier(n_neighbors=params['n_neighbors'])\n",
    "        else:\n",
    "            return KNeighborsClassifier()\n",
    "    if classifier_name == \"naive_bayes\":\n",
    "        return GaussianNB()\n",
    "    if classifier_name == \"svm\":\n",
    "        return SVC()\n",
    "    if classifier_name == \"decision_tree\":\n",
    "        if params:\n",
    "            return tree.DecisionTreeClassifier(max_depth=params['max_depth'], min_samples_split=params['min_samples_split'])\n",
    "        else:\n",
    "            return tree.DecisionTreeClassifier()\n",
    "    if classifier_name == \"random_forest\":\n",
    "        if params:\n",
    "            return RandomForestClassifier(n_estimators=params['n_estimators'])\n",
    "        else:\n",
    "            return RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_evaluation_val(eval_metric, y_test, y_predicted):\n",
    "    if eval_metric == \"accuracy\":\n",
    "        evaluation_val = accuracy_score(y_test, y_predicted)\n",
    "    if eval_metric == \"precision\":\n",
    "        evaluation_val = precision_score(y_test, y_predicted)\n",
    "    if eval_metric == \"recall\":\n",
    "        evaluation_val = recall_score(y_test, y_predicted)\n",
    "    if eval_metric == \"f1\":\n",
    "        evaluation_val = f1_score(y_test, y_predicted)\n",
    "    if eval_metric == \"confusion_matrix\":\n",
    "        evaluation_val = confusion_matrix(y_test, y_predicted)\n",
    "        \n",
    "    \n",
    "    return evaluation_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_for_KNN(X_train, y_train):\n",
    "    \n",
    "    params = {'n_neighbors': [3, 7, 9, 11]}\n",
    "    \n",
    "    knn = get_classifier_obj(\"KNN\", None)\n",
    "    \n",
    "    clf = GridSearchCV(knn, params, scoring=make_scorer(f1_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_K, best_f1_val = clf.best_params_['n_neighbors'], clf.best_score_\n",
    "    print(best_K, best_f1_val)\n",
    "    return best_K, best_f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_decision_tree_params(X_train, y_train):\n",
    "    params = {'max_depth':[2,4,6], 'min_samples_split':[5,10,20] }\n",
    "    df = tree.DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(df, params,scoring=make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.best_params_['max_depth'], clf.best_params_['min_samples_split'] , clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_random_forest_num_estimators(X_train, y_train):\n",
    "    parameters = {'n_estimators':[11,51,71] }\n",
    "    rf = RandomForestClassifier()\n",
    "    clf = GridSearchCV(rf, parameters,scoring=make_scorer(f1_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.best_params_['n_estimators'], clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(X_train, y_train, max_depth_val, min_samples_split_val):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=max_depth_val, min_samples_split=min_samples_split_val)\n",
    "    nb = GaussianNB()\n",
    "    svm = SVC()\n",
    "    \n",
    "    scores = []\n",
    "    algs = [dt,nb,svm]\n",
    "    \n",
    "    for alg in algs : \n",
    "        avg_val_score = cross_val_score(alg, X_train, y_train,scoring=\"recall\", cv=10).mean()\n",
    "        scores.append(avg_val_score)\n",
    "    \n",
    "    best_val = max(scores)\n",
    "    best_clf = algs[scores.index(best_val)]\n",
    "    return best_clf, best_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
