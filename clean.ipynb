{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from lib.preprop import *\n",
    "from lib.geo_to_vector import vectorize_geo\n",
    "from lib.eda_visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45404/1107331204.py:1: DtypeWarning: Columns (18,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('df_complete.csv').iloc[:,3:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13048, 2868)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_complete.csv').iloc[:,3:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10070, 2868)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dups = remove_duplicates(df,['company_name'])\n",
    "df_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting all the columns by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['funding stage','products','raised']\n",
    "cat_cols = ['company_name','company_about', 'founded', 'business model','employees','product stage','status','geographical markets','fund_stage',]\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price']\n",
    "tag_cols = [col for col in df_no_dups.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in df_no_dups.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in df_no_dups.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col  for col in df_no_dups.columns if col.startswith(\"target_industry_\")]\n",
    "technology_list = [col  for col in df_no_dups.columns if col.startswith(\"core_technology_\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Repairing columns</h1>\n",
    "<p> Before removing NaN values, we will first identify what values we expect to have in these columns and we will implement it</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Column 'founded'  </h2>\n",
    "<p>We will change the string representation of founded - \"month/year\" to an integer \"year\"</br>\n",
    "Using REGEX to find the year</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of \"founded\" col is : object\n",
      "\n",
      "Running script..\n",
      "\n",
      "Operation succesfull!\n",
      "type of \"founded\" col is : int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10070, 2868)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing 'founded' column\n",
    "\n",
    "print(f'type of \"founded\" col is : {df_no_dups.founded.dtype}')\n",
    "print('\\nRunning script..')\n",
    "import re\n",
    "founded_pattern = r\"(\\d{4})\"\n",
    "year_list=[]\n",
    "df_founded = df_no_dups.copy()\n",
    "\n",
    "for i, val in enumerate(df_founded.founded) :\n",
    "    year = val.split('/')[-1]\n",
    "    m = re.search(founded_pattern, year)\n",
    "    if m:\n",
    "        year_list.append(int(m.group(0)))\n",
    "        \n",
    "        \n",
    "df_founded['founded'] = year_list\n",
    "\n",
    "\n",
    "print('\\nOperation succesfull!')\n",
    "print(f'type of \"founded\" col is : {df_founded.founded.dtype}')\n",
    "\n",
    "df_founded.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Column 'geographical markets'</h2>\n",
    "<p>The column contains a string representing the geographical markets the company aims for</br>\n",
    "The script lib/geo_to_vector.py calculates the precentage of the market and add it to the dataframe. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographical markets col:\n",
      "0    australia, canada, france, india, united kingd...\n",
      "1                                                  NaN\n",
      "2                 canada, mexico, spain, united states\n",
      "3                                global, united states\n",
      "4    north america, europe, global, france, germany...\n",
      "Name: geographical markets, dtype: object\n",
      "----------------------------------------\n",
      "\n",
      "Running the script...\n",
      "\n",
      "shape of df['geo_market_per']: (10070,)\n",
      "\n",
      "----------------------------------------\n",
      "Operation succesfull!\n",
      "\n",
      "Geographical percentage col:\n",
      "0    0.239983\n",
      "1         NaN\n",
      "2    0.068498\n",
      "3    1.000000\n",
      "4    1.000000\n",
      "Name: geo_market_per, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fixing 'geographical markets' column\n",
    "\n",
    "print(\"Geographical markets col:\")\n",
    "print(df_founded['geographical markets'].head())\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('\\nRunning the script...\\n')\n",
    "df_geo_market = vectorize_geo(df_founded, 'l')\n",
    "\n",
    "print('\\n----------------------------------------')\n",
    "print('Operation succesfull!\\n')\n",
    "print(\"Geographical percentage col:\")\n",
    "print(df_geo_market['geo_market_per'].head())\n",
    "\n",
    "num_cols.append('geo_market_per')\n",
    "cat_cols.remove('geographical markets')\n",
    "df_geo_market = df_geo_market.drop(['geographical markets'], axis=1)\n",
    "df_geo_market = df_geo_market.dropna(subset=['company_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> # Checkpoint : save the new df # </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_geo_market.to_csv('cp1.csv')\n",
    "df_geo_market = pd.read_csv('cp1.csv').iloc[:,1:]\n",
    "df_geo_market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Handling NaN values</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First, we will check how many null values are in each column of the non-binary columns</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values:\n",
      "\ttotal_raised: 5704 missing values\n",
      "\ttotal_rounds: 5704 missing values\n",
      "\tinvestors: 5704 missing values\n",
      "\tipo_price: 9920 missing values\n",
      "\tcompany_name: 0 missing values\n",
      "\tcompany_about: 2 missing values\n",
      "\tfounded: 0 missing values\n",
      "\tbusiness model: 68 missing values\n",
      "\temployees: 32 missing values\n",
      "\tproduct stage: 163 missing values\n",
      "\tstatus: 0 missing values\n",
      "\tfund_stage: 5769 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"missing values:\")\n",
    "cols_to_check = num_cols + cat_cols\n",
    "for col in cols_to_check:\n",
    "    s = df_geo_market[col].isnull().sum()\n",
    "    print(f'\\t{col}: {s} missing values') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num cols: ['total_raised', 'total_rounds', 'investors', 'ipo_price']\n",
      "cat cols: ['company_name', 'company_about', 'founded', 'business model', 'employees', 'product stage', 'status', 'fund_stage']\n"
     ]
    }
   ],
   "source": [
    "print(f\"num cols: {num_cols}\")\n",
    "print(f\"cat cols: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :(10070, 2868)\n",
      "after :(10070, 2865)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'before :{df_geo_market.shape}')\n",
    "new_df = df_geo_market.drop(drop_cols, axis =1)\n",
    "new_df = remove_missing_str_val_rows(new_df, cat_cols)\n",
    "new_df = repair_categorical_missing_vals(new_df, cat_cols)\n",
    "new_df = repair_numeric_missing_vals_zero(new_df, num_cols)\n",
    "\n",
    "\n",
    "print(f'after :{new_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[tag_cols] = new_df[tag_cols].fillna(0)\n",
    "new_df[targetmarket_cols] = new_df[targetmarket_cols].fillna(0)\n",
    "new_df[sector_list] = new_df[sector_list].fillna(0)\n",
    "new_df[target_ind_list] = new_df[target_ind_list].fillna(0)\n",
    "new_df[technology_list] = new_df[technology_list].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matanm/Documents/GitHub/startup_classifier/lib/m.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[i] = decode_price(val)\n"
     ]
    }
   ],
   "source": [
    "for col in num_cols:\n",
    "    new_df[col] = conv_to_float(new_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking missing values in non binary columns...\n",
      "\n",
      "total_raised: 0 missing values\n",
      "total_rounds: 0 missing values\n",
      "investors: 0 missing values\n",
      "ipo_price: 0 missing values\n",
      "company_name: 0 missing values\n",
      "company_about: 0 missing values\n",
      "founded: 0 missing values\n",
      "business model: 0 missing values\n",
      "employees: 0 missing values\n",
      "product stage: 0 missing values\n",
      "status: 0 missing values\n",
      "fund_stage: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking missing values in non binary columns...\\n\")\n",
    "\n",
    "for col in num_cols + cat_cols:\n",
    "    s = new_df[col].isnull().sum()\n",
    "    print(f'{col}: {s} missing values') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking missing values in binary columns...\n",
      "\n",
      "No Nan values in binary columns!\n"
     ]
    }
   ],
   "source": [
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "print(\"Checking missing values in binary columns...\\n\")\n",
    "are_missing = False\n",
    "for col in bin_cols:\n",
    "    s = new_df[col].isnull().sum()\n",
    "    if s!=0:\n",
    "        are_missing = True\n",
    "        print(f'{col}: {s} missing values') \n",
    "if are_missing is False:\n",
    "    print(\"No Nan values in binary columns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> # Checkpoint 2 : save the new df # </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('cp2.csv')\n",
    "# new_df = pd.read_csv('cp2.csv').iloc[:,1:]\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
