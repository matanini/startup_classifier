{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with importing the modules and loading the 3 dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary dataframe shape: (10070, 1927)\n",
      "PCA 2D dataframe shape: (10070, 26)\n",
      "PCA 3D dataframe shape: (10070, 32)\n"
     ]
    }
   ],
   "source": [
    "bin_df = pd.read_csv('data/dataframes/df_after_cols_reduction.csv').iloc[:,1:]\n",
    "pca_2d_df = pd.read_csv('data/dataframes/pca_2d_df.csv').iloc[:,1:]\n",
    "pca_3d_df = pd.read_csv('data/dataframes/pca_3d_df.csv').iloc[:,1:]\n",
    "\n",
    "print(f'Binary dataframe shape: {bin_df.shape}')\n",
    "print(f'PCA 2D dataframe shape: {pca_2d_df.shape}')\n",
    "print(f'PCA 3D dataframe shape: {pca_3d_df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['company_name', 'company_about','founded', 'business model','employees','product stage','status','funding stage','succeeded']\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price', 'geo_market_per']\n",
    "tag_cols = [col for col in bin_df.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in bin_df.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in bin_df.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col  for col in bin_df.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col  for col in bin_df.columns if col.startswith(\"technology_\")]\n",
    "\n",
    "\n",
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "pca_2d_cols = [col for col in pca_2d_df.columns if col not in cat_cols and col not in num_cols]\n",
    "pca_3d_cols = [col for col in pca_3d_df.columns if col not in cat_cols and col not in num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cols : 9\n",
      "Numerical cols : 5\n",
      "Tag cols : 1599\n",
      "Targetmarket cols : 117\n",
      "Sector cols : 41\n",
      "Industry cols : 81\n",
      "Technology cols : 75\n",
      "---- Totals ----\n",
      "Total binary cols : 1913\n",
      "Toatl PCA 2D cols : 12\n",
      "Total PCA 3D cols : 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Categorical cols : {len(cat_cols)}\")\n",
    "print(f\"Numerical cols : {len(num_cols)}\")\n",
    "print(f\"Tag cols : {len(tag_cols)}\")\n",
    "print(f\"Targetmarket cols : {len(targetmarket_cols)}\")\n",
    "print(f\"Sector cols : {len(sector_list)}\")\n",
    "print(f\"Industry cols : {len(target_ind_list)}\")\n",
    "print(f\"Technology cols : {len(technology_list)}\")\n",
    "print('---- Totals ----')\n",
    "print(f\"Total binary cols : {len(bin_cols)}\")\n",
    "print(f\"Toatl PCA 2D cols : {len(pca_2d_cols)}\")\n",
    "print(f\"Total PCA 3D cols : {len(pca_3d_cols)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: (8056, 1786)\n",
      "ytrain shape: (8056,)\n",
      "Xtrain_pca shape: (8056, 17)\n",
      "ytrain_pca shape: (8056,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(bin_df[num_cols + bin_cols], bin_df['succeeded'],test_size = 0.2, stratify=bin_df['succeeded'])\n",
    "Xtrain_pca, Xtest_pca, ytrain_pca, ytest_pca = train_test_split(pca_df[num_cols + pca_cols], bin_df['succeeded'],test_size = 0.2, stratify=bin_df['succeeded'])\n",
    "\n",
    "print(f\"Xtrain shape: {Xtrain.shape}\")\n",
    "print(f\"ytrain shape: {ytrain.shape}\")\n",
    "\n",
    "print(f\"Xtrain_pca shape: {Xtrain_pca.shape}\")\n",
    "print(f\"ytrain_pca shape: {ytrain_pca.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=150)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 150)\n",
    "lr.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred = lr.predict(Xtrain)\n",
    "ytest_pred = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results:\n",
      "accuracy is: 0.7848808341608738\n",
      "precision is: 0.4001384562132226\n",
      "recall is: 1.0\n",
      "f1 is: 0.5715698393077874\n",
      "---------------------\n",
      "Test results:\n",
      "accuracy is: 0.7994041708043694\n",
      "precision is: 0.417027417027417\n",
      "recall is: 1.0\n",
      "f1 is: 0.5885947046843177\n"
     ]
    }
   ],
   "source": [
    "print(\"Train results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"---------------------\")\n",
    "print(\"Test results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train results:  \n",
    "accuracy is: 0.7919563058589871  \n",
    "precision is: 0.4092351075079309  \n",
    "recall is: 1.0  \n",
    "f1 is: 0.5807903951975988  \n",
    "\n",
    "Test results:  \n",
    "accuracy is: 0.79493545183714  \n",
    "precision is: 0.41251778093883357  \n",
    "recall is: 1.0  \n",
    "f1 is: 0.5840886203423967  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 1856)\n",
      "1620.0\n"
     ]
    }
   ],
   "source": [
    "# create a new dataframe with succeeded = 1 and succeeded = 0\n",
    "\n",
    "bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "size = bin_df_succeeded.shape[0]\n",
    "bin_df_fialed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([bin_df_succeeded, bin_df_fialed_sampled])\n",
    "\n",
    "print(equal_df.shape)\n",
    "print(equal_df['succeeded'].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(equal_df[num_cols + bin_cols], equal_df['succeeded'],test_size = 0.2)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred = lr.predict(Xtrain)\n",
    "ytest_pred = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results:\n",
      "accuracy is: 0.8814878892733564\n",
      "precision is: 0.8098542678695351\n",
      "recall is: 1.0\n",
      "f1 is: 0.8949386503067485\n",
      "---------------------\n",
      "Test results:\n",
      "accuracy is: 0.8737024221453287\n",
      "precision is: 0.792022792022792\n",
      "recall is: 1.0\n",
      "f1 is: 0.8839427662957074\n"
     ]
    }
   ],
   "source": [
    "print(\"Train results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"---------------------\")\n",
    "print(\"Test results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape: (2592, 1842)\n",
      "ytrain shape: (2592,)\n",
      "Xtest shape: (648, 1842)\n",
      "ytest shape: (648,)\n",
      "\n",
      "\n",
      "Train results:\n",
      "accuracy is: 0.8969907407407407\n",
      "precision is: 0.9033515198752923\n",
      "recall is: 0.8901689708141322\n",
      "f1 is: 0.8967117988394585\n",
      "---------------------\n",
      "Test results:\n",
      "accuracy is: 0.6882716049382716\n",
      "precision is: 0.6847133757961783\n",
      "recall is: 0.6761006289308176\n",
      "f1 is: 0.680379746835443\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(equal_df[bin_cols], equal_df['succeeded'],test_size = 0.2)\n",
    "\n",
    "print(f\"Xtrain shape: {Xtrain.shape}\")\n",
    "print(f\"ytrain shape: {ytrain.shape}\")\n",
    "print(f\"Xtest shape: {Xtest.shape}\")\n",
    "print(f\"ytest shape: {ytest.shape}\")\n",
    "\n",
    "lr = LogisticRegression(max_iter=1500)\n",
    "lr.fit(Xtrain, ytrain)\n",
    "\n",
    "ytrain_pred = lr.predict(Xtrain)\n",
    "ytest_pred = lr.predict(Xtest)\n",
    "\n",
    "print(\"\\n\\nTrain results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"---------------------\")\n",
    "print(\"Test results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2890, 26)\n",
      "1445.0\n",
      "Xtrain shape: (2312, 12)\n",
      "ytrain shape: (2312,)\n",
      "Xtest shape: (578, 12)\n",
      "ytest shape: (578,)\n",
      "\n",
      "\n",
      "Train results:\n",
      "accuracy is: 0.6600346020761245\n",
      "precision is: 0.6632173095014111\n",
      "recall is: 0.6222418358340689\n",
      "f1 is: 0.6420765027322405\n",
      "---------------------\n",
      "Test results:\n",
      "accuracy is: 0.657439446366782\n",
      "precision is: 0.7050359712230215\n",
      "recall is: 0.6282051282051282\n",
      "f1 is: 0.6644067796610169\n"
     ]
    }
   ],
   "source": [
    "success_rate = 4200000\n",
    "\n",
    "pca_df.loc[(pca_df[\"status\"]==1)&(pca_df['total_raised']>=success_rate), 'succeeded'] = 1\n",
    "pca_df.loc[(pca_df[\"status\"]==0)|(pca_df['total_raised']<success_rate), 'succeeded'] = 0\n",
    "\n",
    "# print(pca_df.head())\n",
    "\n",
    "pca_df_succeeded = pca_df[pca_df['succeeded'] == 1]\n",
    "pca_df_failed = pca_df[pca_df['succeeded'] == 0]\n",
    "\n",
    "size = pca_df_succeeded.shape[0]\n",
    "pca_df_fialed_sampled = pca_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([pca_df_succeeded, pca_df_fialed_sampled])\n",
    "\n",
    "print(equal_df.shape)\n",
    "print(equal_df['succeeded'].sum())\n",
    "\n",
    "pca_cols = [col for col in equal_df.columns if col not in cat_cols and col not in num_cols]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(equal_df[pca_cols], equal_df['succeeded'],test_size = 0.2)\n",
    "\n",
    "print(f\"Xtrain shape: {Xtrain.shape}\")\n",
    "print(f\"ytrain shape: {ytrain.shape}\")\n",
    "print(f\"Xtest shape: {Xtest.shape}\")\n",
    "print(f\"ytest shape: {ytest.shape}\")\n",
    "\n",
    "lr = LogisticRegression(max_iter=1500)\n",
    "lr.fit(Xtrain, ytrain)\n",
    "\n",
    "ytrain_pred = lr.predict(Xtrain)\n",
    "ytest_pred = lr.predict(Xtest)\n",
    "\n",
    "print(\"\\n\\nTrain results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytrain_pred, y_true = ytrain))\n",
    "print(\"---------------------\")\n",
    "print(\"Test results:\")\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"precision is:\",metrics.precision_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"recall is:\",metrics.recall_score(y_pred = ytest_pred, y_true = ytest))\n",
    "print(\"f1 is:\",metrics.f1_score(y_pred = ytest_pred, y_true = ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.unsupervised_learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4054, 1902)\n",
      "2027.0\n"
     ]
    }
   ],
   "source": [
    "bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "size = bin_df_succeeded.shape[0]\n",
    "bin_df_fialed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([bin_df_succeeded, bin_df_fialed_sampled])\n",
    "\n",
    "print(equal_df.shape)\n",
    "print(equal_df['succeeded'].sum())\n",
    "\n",
    "# print(get_best_init_params_for_k_means(equal_df[bin_cols],8,['k-means++','random'],range(5,50,5),42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score after cross-validation: 0.6201803664005068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(max_iter=150)\n",
    "\n",
    "scores = cross_val_score(clf, equal_df[bin_cols], equal_df['succeeded'], cv=cv, scoring='f1_macro')\n",
    "# print(scores)\n",
    "models_scores_dic['LogisticRegression'] = scores.max()\n",
    "print(f'Best score after cross-validation: {scores.max()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro','f1_macro']\n",
    "scores = cross_validate(clf, equal_df[bin_cols], equal_df['succeeded'],cv = cv, scoring=scoring, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_precision_macro: 0.7301166692084795\n",
      "test_recall_macro: 0.7299785663253155\n",
      "test_f1_macro: 0.7299067535220494\n",
      "---------------------\n",
      "train_precision_macro: 0.9012110170399743\n",
      "train_recall_macro: 0.9012798250691363\n",
      "train_f1_macro: 0.9012260996313126\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for d in ['test','train']:\n",
    "    print(f\"{d}_precision_macro: {scores[f'{d}_precision_macro'].max()}\")\n",
    "    print(f\"{d}_recall_macro: {scores[f'{d}_recall_macro'].max()}\")\n",
    "    print(f\"{d}_f1_macro: {scores[f'{d}_f1_macro'].max()}\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6122, 2865)\n",
      "3061.0\n",
      "test_precision_macro: 0.6196110115619267\n",
      "test_recall_macro: 0.619569563432617\n",
      "test_f1_macro: 0.6195489904402395\n",
      "---------------------\n",
      "train_precision_macro: 0.805733760624328\n",
      "train_recall_macro: 0.8050939426279249\n",
      "train_f1_macro: 0.8050638668618363\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "df_outliers = pd.read_csv(\"data/dataframes/final_cleaned.csv\").iloc[:,1:]\n",
    "\n",
    "\n",
    "cat_cols = ['company_name', 'company_about','founded', 'business model','employees','product stage','status','funding stage','succeeded']\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price', 'geo_market_per']\n",
    "tag_cols = [col for col in df_outliers.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in df_outliers.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in df_outliers.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col  for col in df_outliers.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col  for col in df_outliers.columns if col.startswith(\"technology_\")]\n",
    "\n",
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "\n",
    "df_outliers_succeeded = df_outliers[df_outliers['succeeded'] == 1]\n",
    "df_outliers_failed = df_outliers[df_outliers['succeeded'] == 0]\n",
    "\n",
    "size = min(df_outliers_succeeded.shape[0], df_outliers_failed.shape[0])\n",
    "\n",
    "df_outliers_failed_sampled = df_outliers_failed.sample(n = size , random_state = 42)\n",
    "df_outliers_succeded_sampled = df_outliers_succeeded.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([df_outliers_succeded_sampled, df_outliers_failed_sampled])\n",
    "\n",
    "print(equal_df.shape)\n",
    "print(equal_df['succeeded'].sum())\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(max_iter=150)\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro','f1_macro']\n",
    "scores = cross_validate(clf, equal_df[bin_cols], equal_df['succeeded'],cv = cv, scoring=scoring, return_train_score=True)\n",
    "\n",
    "for d in ['test','train']:\n",
    "    print(f\"{d}_precision_macro: {scores[f'{d}_precision_macro'].max()}\")\n",
    "    print(f\"{d}_recall_macro: {scores[f'{d}_recall_macro'].max()}\")\n",
    "    print(f\"{d}_f1_macro: {scores[f'{d}_f1_macro'].max()}\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6122, 1927)\n",
      "3061.0\n"
     ]
    }
   ],
   "source": [
    "bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "size = min(bin_df_succeeded.shape[0], bin_df_failed.shape[0])\n",
    "\n",
    "bin_df_failed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "bin_df_succeded_sampled = bin_df_succeeded.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([bin_df_succeded_sampled, bin_df_failed_sampled])\n",
    "\n",
    "print(equal_df.shape)\n",
    "print(equal_df['succeeded'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(equal_df[bin_cols], equal_df['succeeded'], test_size=0.2, random_state=42)\n",
    "\n",
    "k = 20\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(XTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5551020408163265\n",
      "Precision: 0.6652719665271967\n",
      "Recall: 0.2548076923076923\n",
      "F1: 0.3684820393974507\n",
      "Confusion matrix: \n",
      "[[521  80]\n",
      " [465 159]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(XTest)\n",
    "print(f'Accuracy: {metrics.accuracy_score(yTest, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(yTest, y_pred)}')\n",
    "print(f'Recall: {metrics.recall_score(yTest, y_pred)}')\n",
    "print(f'F1: {metrics.f1_score(yTest, y_pred)}')\n",
    "print(f'Confusion matrix: \\n{metrics.confusion_matrix(yTest, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5149597810590395, Best parameters: {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors':range(1,50,2) }\n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn, parameters,scoring=metrics.make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "print(f'Best score: {clf.best_score_}, Best parameters: {clf.best_params_}')\n",
    "models_scores_dic['KNN'] = clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66559702d8f242a9b806b9475f09f631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "Accuracy: 0.5893877551020408\n",
      "Precision: 0.5990180032733224\n",
      "Recall: 0.5865384615384616\n",
      "F1: 0.5927125506072874\n",
      "\n",
      "poly\n",
      "Accuracy: 0.6024489795918367\n",
      "Precision: 0.6940509915014165\n",
      "Recall: 0.3926282051282051\n",
      "F1: 0.5015353121801434\n",
      "\n",
      "rbf\n",
      "Accuracy: 0.636734693877551\n",
      "Precision: 0.6460032626427407\n",
      "Recall: 0.6346153846153846\n",
      "F1: 0.6402586903799514\n",
      "\n",
      "sigmoid\n",
      "Accuracy: 0.6261224489795918\n",
      "Precision: 0.643598615916955\n",
      "Recall: 0.5961538461538461\n",
      "F1: 0.6189683860232945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import tqdm.notebook as tqdm\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "with tqdm.tqdm(total = len(kernels)) as pbar:\n",
    "    for k in kernels:\n",
    "        clf = svm.SVC(kernel=k, C=1, random_state=42)\n",
    "        clf.fit(XTrain, yTrain)\n",
    "        y_pred = clf.predict(XTest)\n",
    "        print(k)\n",
    "        print(f'Accuracy: {metrics.accuracy_score(yTest, y_pred)}')\n",
    "        print(f'Precision: {metrics.precision_score(yTest, y_pred)}')\n",
    "        print(f'Recall: {metrics.recall_score(yTest, y_pred)}')\n",
    "        print(f'F1: {metrics.f1_score(yTest, y_pred)}\\n')\n",
    "        pbar.update(1)\n",
    "        models_scores_dic[f'SVC_{k}'] = metrics.f1_score(yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5004081632653061\n",
      "Precision: 0.505736137667304\n",
      "Recall: 0.8477564102564102\n",
      "F1: 0.6335329341317366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(XTrain, yTrain)\n",
    "y_pred = gnb.predict(XTest)\n",
    "print(f'Accuracy: {metrics.accuracy_score(yTest, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(yTest, y_pred)}')\n",
    "print(f'Recall: {metrics.recall_score(yTest, y_pred)}')\n",
    "print(f'F1: {metrics.f1_score(yTest, y_pred)}\\n')\n",
    "models_scores_dic['GNB'] = metrics.f1_score(yTest, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n",
      "Precision: 0.5779527559055118\n",
      "Recall: 0.5881410256410257\n",
      "F1: 0.5830023828435267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "dt = decision_tree.fit(XTrain, yTrain)\n",
    "y_pred = dt.predict(XTest)\n",
    "print(f'Accuracy: {metrics.accuracy_score(yTest, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(yTest, y_pred)}')\n",
    "print(f'Recall: {metrics.recall_score(yTest, y_pred)}')\n",
    "print(f'F1: {metrics.f1_score(yTest, y_pred)}\\n')\n",
    "models_scores_dic['DT'] = metrics.f1_score(yTest, y_pred)\n",
    "# renderTree(dt, bin_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6351020408163265\n",
      "Precision: 0.6376360808709176\n",
      "Recall: 0.657051282051282\n",
      "F1: 0.6471981057616417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "trained_forest = forest.fit(XTrain, yTrain)\n",
    "y_pred = trained_forest.predict(XTest)\n",
    "print(f'Accuracy: {metrics.accuracy_score(yTest, y_pred)}')\n",
    "print(f'Precision: {metrics.precision_score(yTest, y_pred)}')\n",
    "print(f'Recall: {metrics.recall_score(yTest, y_pred)}')\n",
    "print(f'F1: {metrics.f1_score(yTest, y_pred)}\\n')\n",
    "models_scores_dic['RF'] = metrics.f1_score(yTest, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5787755102040816\n",
      "Precision: 0.5909090909090909\n",
      "Recall: 0.5625\n",
      "F1: 0.5763546798029557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6114285714285714\n",
      "Precision: 0.6213114754098361\n",
      "Recall: 0.6073717948717948\n",
      "F1: 0.6142625607779578\n",
      "\n",
      "Accuracy: 0.5812244897959183\n",
      "Precision: 0.5857805255023184\n",
      "Recall: 0.6073717948717948\n",
      "F1: 0.5963808025177026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "for solve in ['lbfgs', 'sgd', 'adam']:\n",
    "    clf = MLPClassifier(solver=solve, alpha=1e-5, random_state=42, max_iter=1000)\n",
    "    clf.fit(XTrain, yTrain)\n",
    "    y_pred = clf.predict(XTest)\n",
    "    print(f'Accuracy: {metrics.accuracy_score(yTest, y_pred)}')\n",
    "    print(f'Precision: {metrics.precision_score(yTest, y_pred)}')\n",
    "    print(f'Recall: {metrics.recall_score(yTest, y_pred)}')\n",
    "    print(f'F1: {metrics.f1_score(yTest, y_pred)}\\n')\n",
    "    models_scores_dic[f'MLP_{solve}'] = metrics.f1_score(yTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6471981057616417"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(models_scores_dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d8353be1dd092e57b3f2779bafc40fd4a1c87861698b48ff47a5f1df7325f59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
