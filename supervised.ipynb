{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with importing the modules and loading the 3 dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.unsupervised_learning import *\n",
    "\n",
    "from sklearn import svm, tree, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary dataframe shape: (10070, 1927)\n",
      "PCA 2D dataframe shape: (10070, 26)\n",
      "PCA 3D dataframe shape: (10070, 32)\n"
     ]
    }
   ],
   "source": [
    "bin_df = pd.read_csv('data/dataframes/df_after_cols_reduction.csv').iloc[:,1:]\n",
    "pca_2d_df = pd.read_csv('data/dataframes/pca_2d_df.csv').iloc[:,1:]\n",
    "pca_3d_df = pd.read_csv('data/dataframes/pca_3d_df.csv').iloc[:,1:]\n",
    "\n",
    "print(f'Binary dataframe shape: {bin_df.shape}')\n",
    "print(f'PCA 2D dataframe shape: {pca_2d_df.shape}')\n",
    "print(f'PCA 3D dataframe shape: {pca_3d_df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['company_name', 'company_about','founded', 'business model','employees','product stage','status','funding stage','succeeded']\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price', 'geo_market_per']\n",
    "tag_cols = [col for col in bin_df.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in bin_df.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in bin_df.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col  for col in bin_df.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col  for col in bin_df.columns if col.startswith(\"technology_\")]\n",
    "\n",
    "\n",
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "pca_2d_cols = [col for col in pca_2d_df.columns if col not in cat_cols and col not in num_cols]\n",
    "pca_3d_cols = [col for col in pca_3d_df.columns if col not in cat_cols and col not in num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cols : 9\n",
      "Numerical cols : 5\n",
      "Tag cols : 1599\n",
      "Targetmarket cols : 117\n",
      "Sector cols : 41\n",
      "Industry cols : 81\n",
      "Technology cols : 75\n",
      "---- Totals ----\n",
      "Total binary cols : 1913\n",
      "Toatl PCA 2D cols : 12\n",
      "Total PCA 3D cols : 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Categorical cols : {len(cat_cols)}\")\n",
    "print(f\"Numerical cols : {len(num_cols)}\")\n",
    "print(f\"Tag cols : {len(tag_cols)}\")\n",
    "print(f\"Targetmarket cols : {len(targetmarket_cols)}\")\n",
    "print(f\"Sector cols : {len(sector_list)}\")\n",
    "print(f\"Industry cols : {len(target_ind_list)}\")\n",
    "print(f\"Technology cols : {len(technology_list)}\")\n",
    "print('---- Totals ----')\n",
    "print(f\"Total binary cols : {len(bin_cols)}\")\n",
    "print(f\"Toatl PCA 2D cols : {len(pca_2d_cols)}\")\n",
    "print(f\"Total PCA 3D cols : {len(pca_3d_cols)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this noteook, we will train few machine learning models on our datasets to find the best model to predict the target variable.  \n",
    "The models we will use are:\n",
    "- [Logistic Regression](#lr)\n",
    "- [K-Nearest Neighbours](#knn)\n",
    "- [Support Vector Machine](#svm)\n",
    "- [Gaussian Naive Bayes](#gnb)\n",
    "- [Decision Tree](#dt)\n",
    "- [Random Forest](#rf)\n",
    "- [Multi-layer Perceptron](#mlp)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to prepare our data.  \n",
    "As we saw in the visualizations, we have almost 70% of successful companies in the dataset.  \n",
    "In order to avoid biased results, we need to train the models on an evenly distributed succeeded column in the dataset.  \n",
    "i.e the train data should contain 50% succesfull companies and 50% failed companies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary equal dataframe shape: (6122, 1927)\n",
      "Binary equal dataframe succeeded companies: 3061.0\n"
     ]
    }
   ],
   "source": [
    "bin_df_succeeded = bin_df[bin_df['succeeded'] == 1]\n",
    "bin_df_failed = bin_df[bin_df['succeeded'] == 0]\n",
    "\n",
    "size = min(bin_df_succeeded.shape[0], bin_df_failed.shape[0])\n",
    "\n",
    "bin_df_failed_sampled = bin_df_failed.sample(n = size , random_state = 42)\n",
    "bin_df_succeded_sampled = bin_df_succeeded.sample(n = size , random_state = 42)\n",
    "\n",
    "equal_df = pd.concat([bin_df_succeded_sampled, bin_df_failed_sampled])\n",
    "\n",
    "print(f'Binary equal dataframe shape: {equal_df.shape}')\n",
    "print(f\"Binary equal dataframe succeeded companies: {equal_df['succeeded'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for both pca dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D PCA data:\n",
      "2D PCA equal dataframe shape: (6122, 26)\n",
      "2D PCA equal dataframe succeeded companies: 3061.0\n",
      "\n",
      "3D PCA data:\n",
      "3D PCA equal dataframe shape: (6122, 32)\n",
      "3D PCA equal dataframe succeeded companies: 3061.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2D PCA data:\")\n",
    "\n",
    "pca_2d_df_succeeded = pca_2d_df[pca_2d_df['succeeded'] == 1]\n",
    "pca_2d_df_failed = pca_2d_df[pca_2d_df['succeeded'] == 0]\n",
    "\n",
    "size = min(pca_2d_df_succeeded.shape[0], pca_2d_df_failed.shape[0])\n",
    "\n",
    "pca_2d_df_succeded_sampled = pca_2d_df_succeeded.sample(n = size , random_state = 42)\n",
    "pca_2d_df_failed_sampled = pca_2d_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "pca_2d_equal_df = pd.concat([pca_2d_df_succeded_sampled, pca_2d_df_failed_sampled])\n",
    "\n",
    "print(f'2D PCA equal dataframe shape: {pca_2d_equal_df.shape}')\n",
    "print(f\"2D PCA equal dataframe succeeded companies: {pca_2d_equal_df['succeeded'].sum()}\")\n",
    "\n",
    "print(\"\\n3D PCA data:\")\n",
    "\n",
    "pca_3d_df_succeeded = pca_3d_df[pca_3d_df['succeeded'] == 1]\n",
    "pca_3d_df_failed = pca_3d_df[pca_3d_df['succeeded'] == 0]\n",
    "\n",
    "size = min(pca_3d_df_succeeded.shape[0], pca_3d_df_failed.shape[0])\n",
    "\n",
    "pca_3d_df_succeded_sampled = pca_3d_df_succeeded.sample(n = size , random_state = 42)\n",
    "pca_3d_df_failed_sampled = pca_3d_df_failed.sample(n = size , random_state = 42)\n",
    "\n",
    "pca_3d_equal_df = pd.concat([pca_3d_df_succeded_sampled, pca_3d_df_failed_sampled])\n",
    "\n",
    "print(f'3D PCA equal dataframe shape: {pca_3d_equal_df.shape}')\n",
    "print(f\"3D PCA equal dataframe succeeded companies: {pca_3d_equal_df['succeeded'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_XTrain shape: (4897, 1913)\n",
      "bin_yTrain shape: (4897,)\n",
      "bin_XTest shape: (1225, 1913)\n",
      "bin_yTest shape: (1225,)\n"
     ]
    }
   ],
   "source": [
    "bin_XTrain, bin_XTest, bin_yTrain, bin_yTest = train_test_split(equal_df[bin_cols], equal_df['succeeded'], test_size=0.2, random_state=42, stratify=equal_df['succeeded'])\n",
    "pca_2d_XTrain, pca_2d_XTest, pca_2d_yTrain, pca_2d_yTest = train_test_split(pca_2d_equal_df[pca_2d_cols], pca_2d_equal_df['succeeded'], test_size=0.2, random_state=42, stratify=pca_2d_equal_df['succeeded'])\n",
    "pca_3d_XTrain, pca_3d_XTest, pca_3d_yTrain, pca_3d_yTest = train_test_split(pca_3d_equal_df[pca_3d_cols], pca_3d_equal_df['succeeded'], test_size=0.2, random_state=42, stratify=pca_3d_equal_df['succeeded'])\n",
    "\n",
    "\n",
    "print(f\"bin_XTrain shape: {bin_XTrain.shape}\")\n",
    "print(f\"bin_yTrain shape: {bin_yTrain.shape}\")\n",
    "\n",
    "print(f\"bin_XTest shape: {bin_XTest.shape}\")\n",
    "print(f\"bin_yTest shape: {bin_yTest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create functions to train different models and return the f1 score :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "we will use ShuffleSplit cross validation to train the model. \n",
    "<a id='lr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(df, cols):\n",
    "    cv = ShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "    clf = LogisticRegression(max_iter=150)\n",
    "    scoring = ['f1_macro', 'precision_macro', 'recall_macro','accuracy']\n",
    "    # scores = cross_val_score(clf, df[cols], df['succeeded'], cv=cv, scoring='f1_macro')\n",
    "    scores = cross_validate(clf, df[cols], df['succeeded'], cv=cv, scoring=scoring)\n",
    "    f1 = max(list(scores['test_f1_macro']))\n",
    "    accuracy = max(list(scores['test_precision_macro']))\n",
    "    precision = max(list(scores['test_recall_macro']))\n",
    "    recall = max(list(scores['test_accuracy']))\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours\n",
    "we will use GridSearch to find best parameters for KNN algorithm. \n",
    "<a id='knn'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(XTrain, yTrain):\n",
    "\n",
    "    parameters = {'n_neighbors':range(2,50,2), 'weights':['uniform', 'distance']}\n",
    "    knn = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn, parameters,scoring=metrics.make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(XTrain, yTrain)\n",
    "    y_pred = clf.predict(XTest)\n",
    "    f1 = metrics.f1_score(yTest, y_pred)\n",
    "    accuracy = metrics.accuracy_score(yTest, y_pred)\n",
    "    precision = metrics.precision_score(yTest, y_pred)\n",
    "    recall = metrics.recall_score(yTest, y_pred)\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "we will use GridSearch to find best parameters for SVC algorithm. \n",
    "<a id='svc'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(XTrain, yTrain):\n",
    "    parameters = {'C':[0.1,1,10], 'kernel':['linear', 'rbf']}\n",
    "    s = svm.SVC()\n",
    "    clf = GridSearchCV(s, parameters,scoring=metrics.make_scorer(metrics.f1_score, greater_is_better=True))\n",
    "    clf.fit(XTrain, yTrain)\n",
    "    y_pred = clf.predict(XTest)\n",
    "    f1 = metrics.f1_score(yTest, y_pred)\n",
    "    accuracy = metrics.accuracy_score(yTest, y_pred)\n",
    "    precision = metrics.precision_score(yTest, y_pred)\n",
    "    recall = metrics.recall_score(yTest, y_pred)\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "<a id='gnb'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnb(XTrain, yTrain, XTest, yTest):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(XTrain, yTrain)\n",
    "    y_pred = gnb.predict(XTest)\n",
    "    f1 = metrics.f1_score(yTest, y_pred)\n",
    "    accuracy = metrics.accuracy_score(yTest, y_pred)\n",
    "    precision = metrics.precision_score(yTest, y_pred)\n",
    "    recall = metrics.recall_score(yTest, y_pred)\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "<a id='dt'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dt(XTrain, yTrain, XTest, yTest):\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    dt.fit(XTrain, yTrain)\n",
    "    y_pred = dt.predict(XTest)\n",
    "    f1 = metrics.f1_score(yTest, y_pred)\n",
    "    accuracy = metrics.accuracy_score(yTest, y_pred)\n",
    "    precision = metrics.precision_score(yTest, y_pred)\n",
    "    recall = metrics.recall_score(yTest, y_pred)\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "<a id='rf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(XTrain, yTrain, XTest, yTest):\n",
    "    rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "    rf.fit(XTrain, yTrain)\n",
    "    y_pred = rf.predict(XTest)\n",
    "    f1 = metrics.f1_score(yTest, y_pred)\n",
    "    accuracy = metrics.accuracy_score(yTest, y_pred)\n",
    "    precision = metrics.precision_score(yTest, y_pred)\n",
    "    recall = metrics.recall_score(yTest, y_pred)\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - Multi-layer Perceptron\n",
    "<a id='mlp'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(XTrain, yTrain, XTest, yTest):\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "    mlp.fit(XTrain, yTrain)\n",
    "    y_pred = mlp.predict(XTest)\n",
    "    f1 = metrics.f1_score(yTest, y_pred)\n",
    "    accuracy = metrics.accuracy_score(yTest, y_pred)\n",
    "    precision = metrics.precision_score(yTest, y_pred)\n",
    "    recall = metrics.recall_score(yTest, y_pred)\n",
    "    return  {'test_f1_macro': f1, 'test_accuracy': accuracy, 'test_precision_macro': precision, 'test_recall_macro': recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run every algorithm on the each dataset and compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e850be8bfd2041e9b5c0dceeb451eb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:54.948733, scores: {'test_f1_macro': 0.6040409344741021, 'test_accuracy': 0.6253977513400062, 'test_precision_macro': 0.599258192770106, 'test_recall_macro': 0.6951340615690169}\n",
      "Elapsed time: 0:03:30.154019, scores: {'test_f1_macro': 0.7912159947558177, 'test_accuracy': 0.6837140019860973, 'test_precision_macro': 0.7319587628865979, 'test_recall_macro': 0.8609129814550642}\n"
     ]
    }
   ],
   "source": [
    "# runtime ~ 47 minutes\n",
    "import tqdm.notebook as tqdm\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "dfs_scores = {}\n",
    "t0 = timeit.default_timer()\n",
    "dfs ={'bin_df': (bin_df,bin_cols), 'pca_2d_df': (pca_2d_df,pca_2d_cols), 'pca_3d_df': (pca_3d_df,pca_3d_cols)}\n",
    "with tqdm.tqdm(total=len(dfs)*7) as pbar:\n",
    "    for key, df in dfs.items():\n",
    "        scores = {} \n",
    "        \n",
    "        XTrain, XTest, yTrain, yTest = train_test_split(df[0][df[1]], df[0]['succeeded'], test_size=0.2, random_state=42, stratify=df[0]['succeeded'])\n",
    "\n",
    "        scores['LogisticRegression'] = train_logistic_regression(df[0], df[1])\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"LogisticRegression\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        scores['KNN'] = train_knn(XTrain, yTrain)\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"KNN\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        scores['SVM'] = train_svm(XTrain, yTrain)\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"SVM\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        scores['GNB'] = train_gnb(XTrain, yTrain, XTest, yTest)\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"GNB\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        scores['DT'] = train_dt(XTrain, yTrain, XTest, yTest)\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"DT\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        scores['RF'] = train_rf(XTrain, yTrain, XTest, yTest)\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"RF\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        scores['MLP'] = train_mlp(XTrain, yTrain, XTest, yTest)\n",
    "        print(f'Elapsed time: {timedelta(seconds = timeit.default_timer() - t0)}, scores: {scores[\"MLP\"]}')\n",
    "        pbar.update(1)\n",
    "\n",
    "        dfs_scores[key] = scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {'LogisticRegression': [], 'KNN': [], 'SVM': [], 'GNB': [], 'DT': [], 'RF': [], 'MLP': []}\n",
    "model_list = {}\n",
    "for key, scores in dfs_scores.items():\n",
    "    for model, score in scores.items():\n",
    "        model_scores[model].append(score[1])\n",
    "        model_list[model] = score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "x = ['Binary Data', 'PCA 2D Data', 'PCA 3D Data']\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Logistic Regression', x=x, y=list(model_scores.values())[0]),\n",
    "    go.Bar(name='Knn', x=x, y=list(model_scores.values())[1]),\n",
    "    go.Bar(name='SVM', x=x, y=list(model_scores.values())[2]),\n",
    "    go.Bar(name='GNB', x=x, y=list(model_scores.values())[3]),\n",
    "    go.Bar(name='DT', x=x, y=list(model_scores.values())[4]),\n",
    "    go.Bar(name='RF', x=x, y=list(model_scores.values())[5]),\n",
    "    go.Bar(name='MLP', x=x, y=list(model_scores.values())[6])\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in model_list.items():\n",
    "    y_pred = model.predict(bin_XTest)\n",
    "    print(f\"{key} Accuracy Score: {metrics.accuracy_score(bin_yTest, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d8353be1dd092e57b3f2779bafc40fd4a1c87861698b48ff47a5f1df7325f59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
