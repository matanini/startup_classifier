{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from lib.preprop import *\n",
    "from lib.geo_to_vector import vectorize_geo\n",
    "from lib.eda_visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the dataframe that we scraped from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (18,88) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13048, 2868)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataframes/df_complete.csv').iloc[:,3:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing duplicated rows\n",
    "We will use the `drop_duplicates` method to remove duplicated rows based on 'company_name' column.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10070, 2868)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_dups = remove_duplicates(df,['company_name'])\n",
    "df_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sorting all the columns by groups - categorial, numerical and binary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['company_name','company_about', 'founded', 'business model','employees','product stage','status','geographical markets','fund_stage',]\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price']\n",
    "tag_cols = [col for col in df_no_dups.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in df_no_dups.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in df_no_dups.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col  for col in df_no_dups.columns if col.startswith(\"target_industry_\")]\n",
    "technology_list = [col  for col in df_no_dups.columns if col.startswith(\"core_technology_\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing target_ind_list and technology_list columns to have only 1 underscore:  \n",
    "For example, 'core_technology_ai' will be changed to 'technology_ai'  \n",
    "This will be used later on for the feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_tech_cols = []\n",
    "new_industry_cols = []\n",
    "for col in target_ind_list + technology_list:\n",
    "    if col in technology_list:\n",
    "        new_tech_cols.append(\"technology\" + col[15:])\n",
    "    \n",
    "    elif col in target_ind_list:\n",
    "        new_industry_cols.append(\"industry\" + col[15:])\n",
    "\n",
    "\n",
    "d= {}\n",
    "for i in range(len(new_tech_cols)):\n",
    "    d[technology_list[i]] =  new_tech_cols[i]\n",
    "\n",
    "for i in range(len(new_industry_cols)):\n",
    "    d[target_ind_list[i]] =  new_industry_cols[i]\n",
    "\n",
    "df_no_dups.rename(columns=d, inplace=True)\n",
    "\n",
    "\n",
    "# Update the list with new columns names: \n",
    "\n",
    "target_ind_list = [col for col in df_no_dups.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col for col in df_no_dups.columns if col.startswith(\"technology_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repairing columns  \n",
    "Before removing NaN values, we will first identify what values we expect to have in below columns and we will implement it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column 'founded'\n",
    "We will change the string representation of founded - \"month/year\" to an integer \"year\"  \n",
    "We will use REGEX to find the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of \"founded\" col is : object\n",
      "\n",
      "Running script..\n",
      "\n",
      "Operation succesfull!\n",
      "type of \"founded\" col is : int64\n"
     ]
    }
   ],
   "source": [
    "# Fixing 'founded' column\n",
    "import re\n",
    "\n",
    "print(f'type of \"founded\" col is : {df_no_dups.founded.dtype}')\n",
    "print('\\nRunning script..')\n",
    "\n",
    "founded_pattern = r\"(\\d{4})\"\n",
    "year_list=[]\n",
    "df_founded = df_no_dups.copy()\n",
    "\n",
    "for i, val in enumerate(df_founded.founded) :\n",
    "    year = val.split('/')[-1]\n",
    "    m = re.search(founded_pattern, year)\n",
    "    if m:\n",
    "        year_list.append(int(m.group(0)))\n",
    "        \n",
    "        \n",
    "df_founded['founded'] = year_list\n",
    "\n",
    "\n",
    "print('\\nOperation succesfull!')\n",
    "print(f'type of \"founded\" col is : {df_founded.founded.dtype}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column 'geographical markets'\n",
    "'geographical markets' column contain a string representing the geographical markets the company aims for.  \n",
    "The script in lib.geo_to_vector.py calculates the **precentage** of the target geographic market and add it to the dataframe.  \n",
    "The script uses Selenium to scrape the data from [WorldMeters](https://www.worldometers.info),  \n",
    "Which shows updated data of countries and global population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographical markets col:\n",
      "0    australia, canada, france, india, united kingd...\n",
      "1                                                  NaN\n",
      "2                 canada, mexico, spain, united states\n",
      "3                                global, united states\n",
      "4    north america, europe, global, france, germany...\n",
      "Name: geographical markets, dtype: object\n",
      "----------------------------------------\n",
      "\n",
      "Running the script...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/102.0.5005.61/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\matan\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Operation succesfull!\n",
      "\n",
      "Geographical percentage col:\n",
      "0    0.23971\n",
      "1        NaN\n",
      "2    0.06842\n",
      "3    1.00000\n",
      "4    1.00000\n",
      "Name: geo_market_per, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fixing 'geographical markets' column\n",
    "\n",
    "print(\"Geographical markets col:\")\n",
    "print(df_founded['geographical markets'].head())\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('\\nRunning the script...\\n')\n",
    "df_geo_market = vectorize_geo(df_founded, 'c')\n",
    "\n",
    "print('\\n----------------------------------------')\n",
    "print('Operation succesfull!\\n')\n",
    "print(\"Geographical percentage col:\")\n",
    "print(df_geo_market['geo_market_per'].head())\n",
    "\n",
    "num_cols.append('geo_market_per')\n",
    "cat_cols.remove('geographical markets')\n",
    "\n",
    "df_geo_market = df_geo_market.drop(['geographical markets'], axis=1)\n",
    "df_geo_market = df_geo_market.dropna(subset=['company_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Checkpoint 1 : save the new df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we decided to use checkpoints to save the dataframe after few steps.  \n",
    "This is very helpful with handling the big data we have, and preventing us from running all the code from the top if something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (15,85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10070, 2868)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the desired line\n",
    "\n",
    "# SAVE THE DATA\n",
    "# df_geo_market.to_csv('data/dataframes/cp1.csv')\n",
    "\n",
    "# LOAD THE DATA\n",
    "df_geo_market = pd.read_csv('data/dataframes/cp1.csv').iloc[:,1:]\n",
    "\n",
    "cat_cols = ['company_name','company_about', 'founded', 'business model','employees','product stage','status','funding stage']\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price','geo_market_per']\n",
    "tag_cols = [col for col in df_geo_market.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in df_geo_market.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in df_geo_market.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col for col in df_geo_market.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col for col in df_geo_market.columns if col.startswith(\"technology_\")]\n",
    "\n",
    "\n",
    "df_geo_market.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the cleaning process, we will handle the NaN values.  \n",
    "\n",
    "First, we will check how many null values are in each column of the non-binary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values:\n",
      "\ttotal_raised: 5704 missing values\n",
      "\ttotal_rounds: 5704 missing values\n",
      "\tinvestors: 5704 missing values\n",
      "\tipo_price: 9920 missing values\n",
      "\tgeo_market_per: 2912 missing values\n",
      "\tcompany_name: 0 missing values\n",
      "\tcompany_about: 2 missing values\n",
      "\tfounded: 0 missing values\n",
      "\tbusiness model: 68 missing values\n",
      "\temployees: 32 missing values\n",
      "\tproduct stage: 163 missing values\n",
      "\tstatus: 0 missing values\n",
      "\tfunding stage: 292 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"missing values:\")\n",
    "cols_to_check = num_cols + cat_cols\n",
    "for col in cols_to_check:\n",
    "    s = df_geo_market[col].isnull().sum()\n",
    "    print(f'\\t{col}: {s} missing values') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data scraped from the web, we have 2 columns that represents the same information:  \n",
    "1. 'fund_stage' <-> 'funding stage'\n",
    "2. 'raised' <-> 'total_raised'  \n",
    "\n",
    "Also, we will remove 'products' column since it is not relevant for the analysis.  \n",
    "But first, we will check which of the duplicated columns hold more data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nan values in below columns:\n",
      "\n",
      "'fund_stage' <-> 'funding stage'\n",
      "5769 <-> 292\n",
      "\n",
      "'raised' <-> 'total_raised' \n",
      "6528 <-> 5704\n"
     ]
    }
   ],
   "source": [
    "print(\"Total nan values in below columns:\")\n",
    "print(f\"\\n'fund_stage' <-> 'funding stage'\")\n",
    "print(f\"{df_geo_market['fund_stage'].isnull().sum()} <-> {df_geo_market['funding stage'].isnull().sum()}\")\n",
    "\n",
    "print(f\"\\n'raised' <-> 'total_raised' \")\n",
    "print(f\"{df_geo_market['raised'].isnull().sum()} <-> {df_geo_market['total_raised'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 'fund_stage' has more nan values than 'funding stage', and 'raised' has more nan values than 'total_raised'.  \n",
    "Therefore, we will remove 'fund_stage' and 'raised' columns, in addition to 'products' column.  \n",
    "Also, we will replace nan values in the following way:  \n",
    "1. nan in a **categorical** column will be replaced with 'na'.\n",
    "2. nan in a **numerical** column (except 'geo_market_per' column) will be replaced with 0. \n",
    "3. nan in the **'geo_market_per'** column will be replaced with the median value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before :(10070, 2868)\n",
      "Dataframe shape after :(10070, 2865)\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataframe shape before :{df_geo_market.shape}')\n",
    "\n",
    "drop_cols = ['fund_stage','products','raised']\n",
    "new_df = df_geo_market.drop(drop_cols, axis =1)\n",
    "\n",
    "new_df = repair_categorical_missing_vals(new_df, cat_cols)\n",
    "\n",
    "new_df = repair_numeric_missing_vals_zero(new_df, [col for col in num_cols if col != 'geo_market_per'])\n",
    "new_df = repair_numeric_missing_vals_median(new_df, ['geo_market_per'])\n",
    "\n",
    "print(f'Dataframe shape after :{new_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will convert all numerical columns to float type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "for col in num_cols:\n",
    "    new_df[col] = conv_to_float(new_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking missing values in categorical and numeric columns...\n",
      "\n",
      "total_raised: 0 missing values\n",
      "total_rounds: 0 missing values\n",
      "investors: 0 missing values\n",
      "ipo_price: 0 missing values\n",
      "geo_market_per: 0 missing values\n",
      "company_name: 0 missing values\n",
      "company_about: 0 missing values\n",
      "founded: 0 missing values\n",
      "business model: 0 missing values\n",
      "employees: 0 missing values\n",
      "product stage: 0 missing values\n",
      "status: 0 missing values\n",
      "funding stage: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking missing values in categorical and numeric columns...\\n\")\n",
    "\n",
    "for col in num_cols + cat_cols:\n",
    "    s = new_df[col].isnull().sum()\n",
    "    print(f'{col}: {s} missing values') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dealing with NaN in binary columns  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After handling the nan values in the categorical columns and numeric columns, we can move forward to the massive binary columns.  \n",
    "\n",
    "The scraping process gave a 1 value for each instance (company) only if the specific column key was present in the comapny url,  \n",
    "Therefore, we can replace all nan values in the binary columns with a 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[tag_cols] = new_df[tag_cols].fillna(0)\n",
    "new_df[targetmarket_cols] = new_df[targetmarket_cols].fillna(0)\n",
    "new_df[sector_list] = new_df[sector_list].fillna(0)\n",
    "new_df[target_ind_list] = new_df[target_ind_list].fillna(0)\n",
    "new_df[technology_list] = new_df[technology_list].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will now check if we missed any nan value in the binary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking missing values in binary columns...\n",
      "\n",
      "No Nan values in binary columns!\n"
     ]
    }
   ],
   "source": [
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "\n",
    "print(\"Checking missing values in binary columns...\\n\")\n",
    "are_missing = False\n",
    "\n",
    "for col in bin_cols:\n",
    "    s = new_df[col].isnull().sum()\n",
    "    if s!=0:\n",
    "        are_missing = True\n",
    "        print(f'{col}: {s} missing values') \n",
    "\n",
    "if are_missing is False:\n",
    "    print(\"No Nan values in binary columns!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2 : save the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (82) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe: (10070, 2865)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the desired line\n",
    "\n",
    "# SAVE THE DATA\n",
    "# new_df.to_csv('data/dataframes/cp2.csv')\n",
    "\n",
    "# LOAD THE DATA\n",
    "new_df = pd.read_csv('data/dataframes/cp2.csv').iloc[:,1:]\n",
    "\n",
    "cat_cols = ['company_name','company_about', 'founded', 'business model','employees','product stage','status','funding stage']\n",
    "num_cols = ['total_raised','total_rounds', 'investors','ipo_price', 'geo_market_per']\n",
    "tag_cols = [col for col in new_df.columns if col.startswith('tag_')]\n",
    "targetmarket_cols = [col for col in new_df.columns if col.startswith('targetmarket_')]\n",
    "sector_list = [col for col in new_df.columns if col.startswith(\"sector_\")]\n",
    "target_ind_list = [col for col in new_df.columns if col.startswith(\"industry_\")]\n",
    "technology_list = [col for col in new_df.columns if col.startswith(\"technology_\")]\n",
    "\n",
    "bin_cols = tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list\n",
    "\n",
    "print(f'Shape of the dataframe: {new_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Categorical columns </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's explore the categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_about</th>\n",
       "      <th>founded</th>\n",
       "      <th>business model</th>\n",
       "      <th>employees</th>\n",
       "      <th>product stage</th>\n",
       "      <th>status</th>\n",
       "      <th>funding stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10070</td>\n",
       "      <td>10070</td>\n",
       "      <td>10070.000000</td>\n",
       "      <td>10070</td>\n",
       "      <td>10070</td>\n",
       "      <td>10070</td>\n",
       "      <td>10070</td>\n",
       "      <td>10070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10070</td>\n",
       "      <td>10015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tastewise</td>\n",
       "      <td>This company is a known business entity but la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2B</td>\n",
       "      <td>1-10</td>\n",
       "      <td>Released</td>\n",
       "      <td>active</td>\n",
       "      <td>Bootstrapped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4743</td>\n",
       "      <td>6232</td>\n",
       "      <td>6674</td>\n",
       "      <td>6554</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011.537736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.052327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1901.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company_name                                      company_about  \\\n",
       "count         10070                                              10070   \n",
       "unique        10070                                              10015   \n",
       "top       Tastewise  This company is a known business entity but la...   \n",
       "freq              1                                                 48   \n",
       "mean            NaN                                                NaN   \n",
       "std             NaN                                                NaN   \n",
       "min             NaN                                                NaN   \n",
       "25%             NaN                                                NaN   \n",
       "50%             NaN                                                NaN   \n",
       "75%             NaN                                                NaN   \n",
       "max             NaN                                                NaN   \n",
       "\n",
       "             founded business model employees product stage  status  \\\n",
       "count   10070.000000          10070     10070         10070   10070   \n",
       "unique           NaN             16         6             7       2   \n",
       "top              NaN            B2B      1-10      Released  active   \n",
       "freq             NaN           4743      6232          6674    6554   \n",
       "mean     2011.537736            NaN       NaN           NaN     NaN   \n",
       "std        10.052327            NaN       NaN           NaN     NaN   \n",
       "min      1901.000000            NaN       NaN           NaN     NaN   \n",
       "25%      2010.000000            NaN       NaN           NaN     NaN   \n",
       "50%      2014.000000            NaN       NaN           NaN     NaN   \n",
       "75%      2017.000000            NaN       NaN           NaN     NaN   \n",
       "max      2022.000000            NaN       NaN           NaN     NaN   \n",
       "\n",
       "       funding stage  \n",
       "count          10070  \n",
       "unique            11  \n",
       "top     Bootstrapped  \n",
       "freq            2810  \n",
       "mean             NaN  \n",
       "std              NaN  \n",
       "min              NaN  \n",
       "25%              NaN  \n",
       "50%              NaN  \n",
       "75%              NaN  \n",
       "max              NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df = new_df.copy()\n",
    "cat_df[cat_cols].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that ['employees', 'business model', 'status', 'product stage' and 'funding stage'] columns contains few unique values,  \n",
    "Therefore we can encode them with sklearn's LabelEncoder object.  \n",
    "Lets try it on 'employees' column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for 'employees' column:\n",
      "\n",
      "1-10       6232\n",
      "11-50      2683\n",
      "51-200      822\n",
      "201-500     189\n",
      "500+        112\n",
      "na           32\n",
      "Name: employees, dtype: int64\n",
      "\n",
      "Applying LabelEncoder.\n",
      "\n",
      "New value counts for 'employees' column:\n",
      "\n",
      "0    6232\n",
      "1    2683\n",
      "4     822\n",
      "2     189\n",
      "3     112\n",
      "5      32\n",
      "Name: employees, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Employees col\n",
    "print(\"Value counts for 'employees' column:\\n\")\n",
    "print(cat_df.employees.value_counts())\n",
    "\n",
    "print(\"\\nApplying LabelEncoder.\\n\")\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "cat_df.employees = le.fit_transform(cat_df.employees)\n",
    "print(\"New value counts for 'employees' column:\\n\")\n",
    "print(cat_df.employees.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for the rest of the categorical columns besides 'active',  \n",
    "For the 'active' column, we will use the replace mapping to replace 'active' value with 1 and 'not_active' with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes for each categorical column applied with LabelEncoder :\n",
      "\n",
      "business model:\n",
      "['B2B' 'B2B, B2B2C' 'B2B, B2C' 'B2B, B2C, B2B2C' 'B2B, B2C, B2G'\n",
      " 'B2B, B2C, B2G, B2B2C' 'B2B, B2G' 'B2B, B2G, B2B2C' 'B2B2C' 'B2C'\n",
      " 'B2C, B2B2C' 'B2C, B2G' 'B2C, B2G, B2B2C' 'B2G' 'B2G, B2B2C' 'na']\n",
      "product stage:\n",
      "['Alpha' 'Beta' 'Clinical Trial' 'Customer development' 'R&D' 'Released'\n",
      " 'na']\n",
      "funding stage:\n",
      "['Acquired' 'Bootstrapped' 'Established' 'Pre-Seed' 'Public' 'ROUND A'\n",
      " 'ROUND B' 'ROUND C+' 'Revenue Financed' 'Seed' 'na']\n"
     ]
    }
   ],
   "source": [
    "cols = ['business model', 'product stage', 'funding stage']\n",
    "print(\"Classes for each categorical column applied with LabelEncoder :\\n\")\n",
    "for col in cols:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    cat_df[col] = le.fit_transform(cat_df[col])\n",
    "    print(f'{col}:\\n{le.classes_}')\n",
    "\n",
    "replace_map = {'active' : 1, 'not_active' : 0}\n",
    "cat_df.status.replace(replace_map, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'succeeded' column:\n",
    "After cleaning all the data (categorical, numerical and binary), we can move on to the research part of the project.  \n",
    "In order to check if a company is successful, we will use the following condition:  \n",
    "A company is successful if it has **Product success** or **Funding success**:  \n",
    "1. Product success: \n",
    "    - if 'status' is **active** and 'product stage' is **released**.  \n",
    "<br>\n",
    "2. Funding success:\n",
    "    - if 'funding stage' is **acquired** or\n",
    "    - if 'status' is **active** and 'funding stage' is **public** or\n",
    "    - if 'status' is **active** and 'total raised' is greater than a million dollars.  \n",
    "\n",
    "We will use mask method to add a 'succeeded' column to the dataframe that will hold the success status of each company acording to the above condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total succeeded companies: 7009.0\n"
     ]
    }
   ],
   "source": [
    "# add succeeded column\n",
    "success_rate = 4000000\n",
    "\n",
    "PRODUCT_SUCCESS = (cat_df['status'] == 1) & (cat_df['product stage'] == 5)\n",
    "FUNDING_SUCCESS = (cat_df['funding stage'] == 1) | ((cat_df['funding stage'] == 7) &\n",
    "                  (cat_df['status'] == 1)) | ((cat_df['total_raised'] >= success_rate) &\n",
    "                  (cat_df['status'] == 1))\n",
    "\n",
    "cat_df.loc[PRODUCT_SUCCESS | FUNDING_SUCCESS , 'succeeded'] = 1\n",
    "cat_df.loc[~PRODUCT_SUCCESS & ~FUNDING_SUCCESS, 'succeeded'] = 0\n",
    "\n",
    "# Add the new succeeded column to categorical columns list: \n",
    "cat_cols.append('succeeded')\n",
    "\n",
    "print(f'Total succeeded companies: {cat_df.succeeded.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the cleaned dataframe\n",
    "We will now save the cleaned dataframe as csv file and change columns order in the following way:  \n",
    "cat_cols, num_cols, tag_cols, targetmarket_cols, sector_list, target_ind_list, technology_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(cat_df, columns = cat_cols + num_cols + tag_cols + targetmarket_cols + sector_list + target_ind_list + technology_list)\n",
    "final_df.to_csv('data/dataframes/final_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we took the raw scraped dataframe and cleaned it.  \n",
    "Next step is to detect the outliers in the dataframe.  \n",
    "It is complicated to find relationship between binary columns, and we will tackle it in the next notebook: [Outlier detection notebook](3-outlier-detection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d8353be1dd092e57b3f2779bafc40fd4a1c87861698b48ff47a5f1df7325f59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
