{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------>>>>>>>> RUN THIS CODE CELL <<<<<<<<------------\n",
    "# === CELL TYPE: IMPORTS AND SETUP \n",
    "\n",
    "import os                       # for testing use only\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "# pip install seaborn\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "\n",
    "from sklearn import metrics, preprocessing, neighbors, cluster\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "# Create color maps\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap([\"#e41a1c\",\"#984ea3\",\"#a65628\",\"#377eb8\",\"#ffff33\",\"#4daf4a\",\"#ff7f00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    return pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_values(dataset):\n",
    "    df = dataset.copy()\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(dataset):\n",
    "    df = dataset.copy()\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_str_to_numeric_vals(dataset,str_col,id_col_to_remove):\n",
    "    df = dataset.copy()\n",
    "    df[str_col] = sklearn.preprocessing.LabelEncoder().fit_transform(df[str_col])\n",
    "    df.drop(columns=id_col_to_remove, inplace=True, axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataset):\n",
    "    df = dataset.copy()\n",
    "    scaler = StandardScaler()\n",
    "    dataset_scaled = scaler.fit_transform(df)\n",
    "    return dataset_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_k_means(dataset, num_clusters, init_val, n_init_val, rand_state):\n",
    "    df = dataset.copy()\n",
    "    model = KMeans(n_clusters=num_clusters, n_init=n_init_val, init=init_val, random_state=rand_state)\n",
    "    predicted_vals = model.fit_predict(dataset)\n",
    "    return model, predicted_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hierarchical_clustering(dataset, num_clusters, linkage_val):\n",
    "    model = AgglomerativeClustering(n_clusters=num_clusters, linkage=linkage_val)\n",
    "    predicted_vals = model.fit_predict(dataset)\n",
    "    return model, predicted_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_density_based_clustering(dataset, epsilon_val, minimum_samples_val):\n",
    "    model = DBSCAN(eps=epsilon_val, min_samples=minimum_samples_val)\n",
    "    predicted_vals = model.fit_predict(dataset)\n",
    "    \n",
    "    return model, predicted_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_init_params_for_k_means(dataset, num_clusters, init_options, n_init_options, rand_state):\n",
    "    scores = []\n",
    "    results = {}\n",
    "    best_score, best_init_val, best_n_init_val = -1, None, None\n",
    "    for n in n_init_options:\n",
    "        for option in init_options:\n",
    "            km, predicted_vals = perform_k_means(dataset, num_clusters, option, n, rand_state)\n",
    "            score = km.inertia_\n",
    "            scores.append(score)\n",
    "            results[score] = {\"option\": option, \"n\": n}\n",
    "    \n",
    "    scores.sort(reverse=True)\n",
    "    \n",
    "    for i in range(1, len(scores)):\n",
    "        score = scores[i]\n",
    "        if(scores[i-1] / scores[i] > 1.01):\n",
    "            best_score = scores[i]\n",
    "        \n",
    "    return best_score, results[best_score]['option'], results[best_score]['n']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_number_of_clusters(dataset, num_cluster_options, init_val, n_init_val, rand_state):\n",
    "    scores = []\n",
    "    for k in num_cluster_options:\n",
    "        km, predicted_vals = perform_k_means(dataset, k, init_val, n_init_val, rand_state)\n",
    "        scores.append(km.inertia_)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_num_of_clusters_for_k_means(dataset, num_cluster_options, init_val, n_init_val, rand_state):\n",
    "    scores = []\n",
    "    clusters = {}\n",
    "    best_score=0\n",
    "    for k in num_cluster_options:\n",
    "        km, predicted_vals = perform_k_means(dataset, k, init_val, n_init_val, rand_state)\n",
    "        score = silhouette_score(dataset, predicted_vals)\n",
    "        clusters[score] = k\n",
    "        scores.append(score)\n",
    "        if(score>best_score):\n",
    "            best_score = score\n",
    "            num_clusters =k\n",
    "    \n",
    "    return best_score, num_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_linkage_method(dataset, num_clusters, linkage_options):\n",
    "    scores = []\n",
    "    clusters = {}\n",
    "    best_score=0\n",
    "    best_linkage = None\n",
    "    for linkage_val in linkage_options:\n",
    "        model, y_pred = perform_hierarchical_clustering(dataset, num_clusters, linkage_val)\n",
    "        score = silhouette_score(dataset, y_pred)\n",
    "        clusters[score] = linkage_val\n",
    "        scores.append(score)\n",
    "        if(score>best_score):\n",
    "            best_score = score\n",
    "            best_linkage = linkage_val\n",
    "            \n",
    "    return best_score, best_linkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_for_dbscan(dataset, eps_options, min_samples_options):\n",
    "    scores = []\n",
    "    results = {}\n",
    "    \n",
    "    for minimum_samples_val in min_samples_options:\n",
    "        for epsilon_val in eps_options:\n",
    "            model, predicted_vals = perform_density_based_clustering(dataset, epsilon_val, minimum_samples_val)\n",
    "            score = silhouette_score(dataset, predicted_vals)\n",
    "            scores.append(score)\n",
    "            results[score] = {\"minimum_samples_val\": minimum_samples_val, \"epsilon_val\": epsilon_val}\n",
    "    best_score = max(scores)\n",
    "   \n",
    "    return best_score, results[best_score]['epsilon_val'], results[best_score]['minimum_samples_val']\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
